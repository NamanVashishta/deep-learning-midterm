{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":627515,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":472502,"modelId":488398}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"unsloth[colab-new]\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T02:13:21.911614Z","iopub.execute_input":"2025-11-02T02:13:21.912386Z","iopub.status.idle":"2025-11-02T02:13:26.365357Z","shell.execute_reply.started":"2025-11-02T02:13:21.912354Z","shell.execute_reply":"2025-11-02T02:13:26.364638Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: unsloth[colab-new] in /usr/local/lib/python3.11/dist-packages (2025.10.12)\nRequirement already satisfied: unsloth_zoo>=2025.10.13 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (2025.10.13)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (2.8.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.23.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (7.1.0)\nRequirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.9.35)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (3.20.3)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.0.32.post2)\nRequirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.48.2)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (3.4.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.2.0)\nRequirement already satisfied: datasets!=4.0.*,!=4.1.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (4.1.1)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (1.9.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.16.0)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.34.0)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (4.57.1)\nRequirement already satisfied: trl!=0.19.0,<=0.23.0,>=0.18.2 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.23.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (6.0.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.19.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.32.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (0.70.16)\nRequirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth[colab-new]) (2.4.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.1.3)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth[colab-new]) (75.2.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (2025.9.18)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (0.22.1)\nRequirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.13->unsloth[colab-new]) (0.14.1)\nRequirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.13->unsloth[colab-new]) (25.1.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.13->unsloth[colab-new]) (11.3.0)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.13->unsloth[colab-new]) (0.19.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (14.1.0)\nRequirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (1.7.2)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n\u001b[33mWARNING: unsloth 2025.10.12 does not provide the extra 'triton'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.12.15)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.8.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[colab-new]) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth[colab-new]) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth[colab-new]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth[colab-new]) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth[colab-new]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth[colab-new]) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth[colab-new]) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.17.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import the 'os' library to interact with the operating system\nimport os\n\n# --- Environment Check ---\n# We check for an environment variable 'COLAB_GPU'. If it exists, we're in Google Colab.\nif 'COLAB_GPU' in os.environ:\n    print(\"Running in Google Colab.\")\n    # Google Drive mounting happens inside train.py if needed.\n    # We set the SAVE_PATH variable here mainly for the post-training steps.\n    SAVE_PATH = \"/content/drive/MyDrive/llama3_math_checkpoint\"\n\n# We check if the /kaggle/input directory exists. If it does, we're in a Kaggle Notebook.\nelif os.path.exists('/kaggle/input'):\n    print(\"Running in Kaggle Notebook.\")\n    # Set the save path to Kaggle's writable directory\n    SAVE_PATH = \"/kaggle/working/llama3_math_checkpoint\"\n\nelse:\n    print(\"Running in a local environment.\")\n    # Set a default path for a local machine\n    SAVE_PATH = \"llama3_math_checkpoint\"\n\n# --- Create Save Directory ---\n# 'os.makedirs' creates the directory if it doesn't already exist.\n# 'exist_ok=True' prevents an error if the folder is already there.\n# We still create the directory here in case post-processing steps need it,\n# although train.py will also create it.\nos.makedirs(SAVE_PATH, exist_ok=True)\n\nprint(f\"Post-training model checkpoint location set to: {SAVE_PATH}\")\nprint(\"Cell 4 Complete: Environment check done.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T02:13:26.366794Z","iopub.execute_input":"2025-11-02T02:13:26.367456Z","iopub.status.idle":"2025-11-02T02:13:26.374038Z","shell.execute_reply.started":"2025-11-02T02:13:26.367423Z","shell.execute_reply":"2025-11-02T02:13:26.373205Z"}},"outputs":[{"name":"stdout","text":"Running in Kaggle Notebook.\nPost-training model checkpoint location set to: /kaggle/working/llama3_math_checkpoint\nCell 4 Complete: Environment check done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile train.py\n# --- 1. IMPORTS ---\nimport torch\nfrom unsloth import FastLanguageModel\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, EarlyStoppingCallback, AutoTokenizer\nimport os\nfrom accelerate import Accelerator\nimport pandas as pd\nfrom tqdm import tqdm\n\n# --- 2. INITIALIZE ACCELERATOR ---\naccelerator = Accelerator()\nprint(f\"train.py: Process rank: {accelerator.process_index}, Device: {accelerator.device}, Main process: {accelerator.is_main_process}\")\n\n# --- 3. ENVIRONMENT AND SAVE PATH (DYNAMIC) ---\n# (Your friend's logic here is perfect)\nif 'COLAB_GPU' in os.environ:\n    print(\"train.py: Running in Google Colab.\")\n    SAVE_PATH = \"llama3_math_checkpoint_colab_local\"\nelif os.path.exists('/kaggle/input'):\n    print(\"train.py: Running in Kaggle Notebook.\")\n    SAVE_PATH = \"/kaggle/working/llama3_math_checkpoint\"\nelse:\n    print(\"train.py: Running in a local environment.\")\n    SAVE_PATH = \"llama3_math_checkpoint\"\n\nif accelerator.is_main_process: os.makedirs(SAVE_PATH, exist_ok=True)\naccelerator.wait_for_everyone()\nprint(f\"train.py: Model checkpoint save path: {SAVE_PATH}\")\n\n# --- 4. LOAD MODEL AND TOKENIZER ---\nmax_seq_length = 4096  # <--- FIX #1: Use 4096 for long problems\ndtype = None\nload_in_4bit = True\n\nload_model_kwargs = {\n    \"max_seq_length\": max_seq_length,\n    \"dtype\": dtype,\n    \"load_in_4bit\": load_in_4bit,\n}\n\nif accelerator.num_processes == 1:\n    print(\"Single-GPU setup. Using device_map='auto'.\")\n    load_model_kwargs[\"device_map\"] = \"auto\"\nelse:\n    print(f\"Multi-GPU setup ({accelerator.num_processes} processes). Using accelerate device_map.\")\n    load_model_kwargs[\"device_map\"] = {\"\": accelerator.device}\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/Meta-Llama-3.1-8B\",\n    **load_model_kwargs,\n)\n\n# --- Apply LoRA ---\nmodel = FastLanguageModel.get_peft_model(\n    model, r=16, lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_dropout=0, bias=\"none\", use_gradient_checkpointing=\"unsloth\", random_state=42,\n)\n\n# --- 5. PREPARE DATASET ---\ndataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"train\")\nshuffled_dataset = dataset.shuffle(seed=42)\n\n# <--- FIX #2: Use 100,000 samples for a real model ---\ntrain_subset = shuffled_dataset.select(range(60000))\n# <--- FIX #2: Use 10,000 samples for validation ---\neval_subset = shuffled_dataset.select(range(60000, 65000)) \n\n# (Your friend's prompt template is perfect)\ntraining_prompt_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\nYou are a meticulous math solution verifier. Your task is to carefully analyze the 'Provided Solution' step-by-step to determine if it logically and correctly reaches the 'Expected Answer' for the given 'Question'. Respond ONLY with 'True' if the solution's reasoning AND final result are correct and match the expected answer, otherwise respond ONLY with 'False'.<|eot_id|><|start_header_id|>user<|end_header_id|>\nQuestion:\n{}\n\nExpected Answer:\n{}\n\nProvided Solution:\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n{}<|eot_id|>\"\"\"\n\ndef formatting_prompts_func(examples):\n    questions, solutions, answers = examples[\"question\"], examples[\"solution\"], examples[\"answer\"]\n    outputs = [str(x) for x in examples[\"is_correct\"]]\n    texts = []\n    for question, solution, answer, output in zip(questions, solutions, answers, outputs):\n        text = training_prompt_template.format(question, str(answer), str(solution), output)\n        texts.append(text)\n    return { \"text\" : texts }\n\ntry: num_proc = os.cpu_count() // 2 if os.cpu_count() else 4\nexcept: num_proc = 4\n\nwith accelerator.main_process_first():\n    final_train_dataset = train_subset.map(formatting_prompts_func, batched=True, num_proc=num_proc)\n    final_eval_dataset = eval_subset.map(formatting_prompts_func, batched=True, num_proc=num_proc)\n\nprint(f\"train.py Process {accelerator.process_index}: Dataset prepared: {len(final_train_dataset)} train / {len(final_eval_dataset)} eval examples.\")\n\n# --- 6. SET UP TRAINER ---\ntraining_args = TrainingArguments(\n    output_dir=\"training_outputs\",\n    num_train_epochs=1,\n    \n    # <--- FIX #3: Use batch size 2 to fit 4096 seq length in VRAM ---\n    per_device_train_batch_size = 2,\n    per_device_eval_batch_size = 1, # (This is correct)\n    # <--- FIX #4: Increase accumulation to compensate for batch size ---\n    gradient_accumulation_steps = 8, \n    \n    optim=\"adamw_8bit\",\n    weight_decay=0.01,\n    logging_steps=100,\n    learning_rate=1e-4,\n    fp16=not torch.cuda.is_bf16_supported(),\n    bf16=torch.cuda.is_bf16_supported(),\n    seed=42,\n    report_to=\"none\",\n    eval_strategy=\"steps\", # <--- Changed to steps\n    eval_steps=1000,       # <--- Evaluate every 1000 steps\n    save_strategy=\"steps\", # <--- Changed to steps\n    save_steps=1000,       # <--- Save every 1000 steps\n    load_best_model_at_end=True,\n    save_total_limit=2,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    ddp_find_unused_parameters=False,\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_args,\n    train_dataset=final_train_dataset,\n    eval_dataset=final_eval_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length, # <--- Will now be 4096\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n    packing=False,\n)\n\n# --- 7. START TRAINING ---\nprint(f\"--- ðŸš€ Process {accelerator.process_index}: Starting Model Training ---\")\ntrainer.train()\nprint(f\"--- âœ… Process {accelerator.process_index}: Model Training Complete ---\")\n\n# --- 8. SAVE FINAL MODEL (Only on Main Process) ---\naccelerator.wait_for_everyone()\nif accelerator.is_main_process:\n    print(f\"Saving final model checkpoint to {SAVE_PATH}\")\n    trainer.model.save_pretrained(SAVE_PATH)\n    tokenizer.save_pretrained(SAVE_PATH)\n    print(f\"âœ… Model adapters and tokenizer saved to: {SAVE_PATH}\")\nelse:\n    print(f\"Process {accelerator.process_index}: Skipping save.\")\naccelerator.wait_for_everyone()\nprint(f\"train.py: Process {accelerator.process_index} finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T02:13:26.374904Z","iopub.execute_input":"2025-11-02T02:13:26.375106Z","iopub.status.idle":"2025-11-02T02:13:26.392890Z","shell.execute_reply.started":"2025-11-02T02:13:26.375082Z","shell.execute_reply":"2025-11-02T02:13:26.392260Z"}},"outputs":[{"name":"stdout","text":"Overwriting train.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"Cell 10: Launching training script...\")\nimport torch\nimport os\n\n# --- Launch the training script using accelerate ---\nif torch.cuda.is_available():\n    num_processes = torch.cuda.device_count()\n    print(f\"Found {num_processes} GPU(s). Launching with {num_processes} processes.\")\n    command = f\"accelerate launch --num_processes={num_processes} train.py\"\nelse:\n    num_processes = 1\n    print(\"No GPU found. Launching with 1 CPU process.\")\n    command = f\"accelerate launch --num_processes={num_processes} --cpu train.py\"\n\nprint(f\"Running command: {command}\")\n\n# Use ! instead of os.system() to see live output and errors\n!{command}\n\nprint(\"Cell 10 Complete: Training script finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T02:13:26.393646Z","iopub.execute_input":"2025-11-02T02:13:26.393868Z"}},"outputs":[{"name":"stdout","text":"Cell 10: Launching training script...\nFound 2 GPU(s). Launching with 2 processes.\nRunning command: accelerate launch --num_processes=2 train.py\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-11-02 02:13:40.298009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-11-02 02:13:40.299021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762049620.343907     928 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762049620.346644     927 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762049620.358669     928 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1762049620.361083     927 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\ntrain.py: Process rank: 0, Device: cuda:0, Main process: True\ntrain.py: Running in Kaggle Notebook.\n[rank0]:[W1102 02:14:01.867697628 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\ntrain.py: Process rank: 1, Device: cuda:1, Main process: False\ntrain.py: Running in Kaggle Notebook.\n[rank1]:[W1102 02:14:01.389355064 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\ntrain.py: Model checkpoint save path: /kaggle/working/llama3_math_checkpointtrain.py: Model checkpoint save path: /kaggle/working/llama3_math_checkpoint\n\nMulti-GPU setup (2 processes). Using accelerate device_map.Multi-GPU setup (2 processes). Using accelerate device_map.\n\n==((====))==  Unsloth 2025.10.12: Fast Llama patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n==((====))==  Unsloth 2025.10.12: Fast Llama patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth 2025.10.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\nUnsloth 2025.10.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\nMap (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60000/60000 [00:01<00:00, 37932.75 examples/s]\nMap (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 9015.67 examples/s]\ntrain.py Process 0: Dataset prepared: 60000 train / 5000 eval examples.\ntrain.py Process 1: Dataset prepared: 60000 train / 5000 eval examples.\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|â–ˆ| 60000/60000 [00:56<00:00, 105\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|â–ˆ| 60000/60000 [00:57<00:00, 104\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|â–ˆ| 5000/5000 [00:11<00:00, 426.1\n--- ðŸš€ Process 1: Starting Model Training ---\nThe model is already on multiple devices. Skipping the move to device specified in `args`.\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|â–ˆ| 5000/5000 [00:12<00:00, 413.2\n--- ðŸš€ Process 0: Starting Model Training ---\nThe model is already on multiple devices. Skipping the move to device specified in `args`.\nUnsloth is running with multi GPUs - the effective batch size is multiplied by 2\nUnsloth is running with multi GPUs - the effective batch size is multiplied by 2\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 60,000 | Num Epochs = 1 | Total steps = 1,875\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 2 | Total batch size (2 x 8 x 2) = 32\n \"-____-\"     Trainable parameters = 41,943,040 of 4,670,623,744 (0.90% trained)\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 60,000 | Num Epochs = 1 | Total steps = 1,875\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 2 | Total batch size (2 x 8 x 2) = 32\n \"-____-\"     Trainable parameters = 41,943,040 of 4,670,623,744 (0.90% trained)\n  0%|                                                  | 0/1875 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\nUnsloth: Will smartly offload gradients to save VRAM!\n{'loss': 0.9229, 'grad_norm': 0.13325248658657074, 'learning_rate': 9.472000000000001e-05, 'epoch': 0.05}\n{'loss': 0.7681, 'grad_norm': 0.12860091030597687, 'learning_rate': 8.938666666666667e-05, 'epoch': 0.11}\n{'loss': 0.7593, 'grad_norm': 0.10730158537626266, 'learning_rate': 8.405333333333334e-05, 'epoch': 0.16}\n{'loss': 0.7386, 'grad_norm': 0.12133810669183731, 'learning_rate': 7.872e-05, 'epoch': 0.21}\n{'loss': 0.7386, 'grad_norm': 0.12323886156082153, 'learning_rate': 7.338666666666667e-05, 'epoch': 0.27}\n{'loss': 0.7271, 'grad_norm': 0.11749803274869919, 'learning_rate': 6.805333333333334e-05, 'epoch': 0.32}\n{'loss': 0.7266, 'grad_norm': 0.14600855112075806, 'learning_rate': 6.272e-05, 'epoch': 0.37}\n{'loss': 0.7199, 'grad_norm': 0.17576079070568085, 'learning_rate': 5.7386666666666664e-05, 'epoch': 0.43}\n 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 809/1875 [5:00:39<7:02:07, 23.76s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}